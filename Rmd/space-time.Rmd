---
title: "Space-time plots"
author: "Lyndon Estes"
date: "December 3, 2015"
output: 
  html_document:
    toc: yes
    number_sections: true
    toc_depth: 3
---

# Space versus time analysis
```{r, message = FALSE, warning=FALSE, results='hold'}
library(ecoscales)
library(readxl)
library(stringdist)
library(maptools)
library(RColorBrewer)

p_root <- set_base_path("ecoscales")
p_dat <- full_path(p_root, "external/data/result")
p_calib <- full_path(p_root, "external/data/calibration")
# dat <- as.data.table(read_excel(full_path(p_dat, "merged.xlsx")))
dat <- as.data.table(read_excel(full_path(p_dat, "mergedfff.xlsx")))
cal <- data.table(read_excel(fp(p_calib, "merged_calibrationffff.xlsx")))
full <- data.table(read_excel(fp(p_dat, "full_less_Treuer.xlsx")))

setnames(dat, "DOI/title", "DOI")
dat[, DOI := gsub("DOI:|doi:|DOI: |doi: |DOI ", "", DOI)]
dat[, DOI := gsub("\\s", "", DOI)]  # remove DOI and whitespace
full <- gsub("DOI:|doi:|DOI: |doi: |DOI ", "", full$DOI)
full <- gsub("\\s", "", full)  # remove DOI and whitespace

dat <- dat[, names(dat)[1:20], with = FALSE]

unique(dat$study_type)
dat[, study_type := tolower(study_type)]
kwords <- c("field", "paleo", "remote", "automated", "other")
for(i in 1:length(kwords)) dat[like(study_type, kwords[i]), st := i]

# dat[st == 5, .N] / nrow(dat)

# class(cal$DOI)
# class(dat$DOI)
# unique(cal$DOI) %in% unique(dat$DOI)
# match(cal$DOI, dat$DOI)
# match(dat$DOI, cal$DOI)
# dat[dat$DOI %in% cal$DOI, DOI]
# dat[cal$DOI %in% dat$DOI, ]
# cal[DOI == dat[cal$DOI %in% dat$DOI, DOI][11]]
# dat[DOI == dat[cal$DOI %in% dat$DOI, DOI][7]]

```

## Data prep
### Merge full and calibration datasets
```{r, message=FALSE, warning=FALSE, results='hide'}
dat2 <- copy(dat[, .(st, DOI, study_type, plot_res, n_sites, sampled_area,
                     samp_duration, t_btwn_samp, study_duration)])
rnms <- c("st", "DOI", "study_type", "feature", "observer", "plot_res", 
          "n_sites", "sampled_area", "t_btwn_samp", "study_duration")
calr <- cal[, rnms, with = FALSE]
for(j in names(calr)[c(4, 6:10)]) set(calr, j=j, value = as.numeric(calr[[j]]))

# select down to columns of interest
# st <- calr$study_type[which(calr$feature != 99)]
calr <- calr[feature != 99, lapply(.SD, mean), by = .(DOI, feature), 
             .SDcols = rnms[c(1, 6:10)]]
length(unique(calr$DOI)) + length(unique(dat$DOI))  # 140 papers providing dat
unique(calr$DOI)
calr_type <- data.table(cbind("DOI" = unique(calr$DOI), # calib field studies
                              "study_type" = c(rep("field", 5), "paleo",
                                               rep("field", 4)))) 

# combine full and calibration
calr[, samp_duration := NA]
calr[, "feature" := NULL] #c("DOI", "feature") := NULL]
calr <- merge(calr, calr_type, by = "DOI")
setcolorder(calr, names(calr)[c(2:1, 9, 3:5, 8, 6:7)])
datf <- rbind(cbind("dsrc" = 1, dat2), cbind("dsrc" = 2, calr))

doisup <- c(unique(cal$DOI_data_source), unique(dat$DOI_data_source))
doisup <- doisup[!is.na(doisup) & doisup != "NA" & doisup != "-"]
doisup <- unlist(strsplit(doisup, ";"))

```

`r length(unique(datf$DOI))` papers  main analysis

`r length(unique(full)) + 20 + 57` papers main analysis (everyone's but Tim's)

`r (length(unique(full)) + 20 + 57) / 42918 * 100` % of all papers since 2004

`r length(unique(doisup))` additional papers or other publications tracked down

`r nrow(datf)` records (ecological observations)

<a href="#top">Back to top</a>

### Adjustments/fixes
1. if `samp_duration != study_duration` and `t_btwn_samp == 0`, set `study_duration == samp_duration` (actually, no, in many cases there is a good reason to have to `study_duration != samp_duration` (see below))
2. Prior to scaling the data in log10 space, we need to make one adjustment. Time between samples has many 0 values because many observations are simply one-offs.  Set these to an arbitrarily large value which will represent clear separation on axis from high frequency studies. A function is defined here for this purpose, and will be applied after bootstrapping is done. 

```{r, message=FALSE, warning=FALSE, results='hide'}
# apply fixes (mostly to account for observer omissions)
# 1. if samp_duration != study_duration and t_btwn_samp == 0, set 
#    study_duration == samp_duration
names(datf)
datf[t_btwn_samp == 0 & (study_duration != samp_duration), ]  
dat[t_btwn_samp == 0 & (study_duration != samp_duration), c(1, 3, 8:13), with=F]  
# function to set t_btwn_samp to 365 * 100000 to indicate once-off studies 
# when t_btwn_samp == 0.  
to_infin_byond <- function(tbtwn) ifelse(tbtwn == 0, 365 * 10000, tbtwn)

```

<a href="#top">Back to top</a>

## Analyses
### Resampling with uncertainties

Defined by the per variable CV based on uncertainty between observers. Here we are just going to use apply the variability to each variable for every observation (previous incarnation used uncertainty on just the variables listed as uncertain, with recalculation of dependent variables (`study_duration`, `sampled_area`) made after pertubation [see commit prior to second or third commit on 4 April for code]).

```{r, eval=FALSE}
# p <- c(0.64, 0.84, 0.53, 1.21)  # from calibration.Rmd
p <- c(0.58, 0.82, 0.99, 1.24)  # from calibration.Rmd

# Function for bootstrapping with uncertainties
resamp_func <- function(dat, p, iter) {
  bout <- lapply(1:iter, function(x) {
    if((x / 100) %in% 1:100) print(x)
    if(length(p) < 4) stop("p must be length of 4", call. = FALSE)
    
    dnew <- copy(datf[, .(plot_res, sampled_area, t_btwn_samp, study_duration)])
    # modifiers
    modvec <- sapply(p, function(y) {
      mv <- runif(nrow(dnew), min = 1 - y, max = 1 + y)
      mv
    })

    for(j in 1:ncol(modvec)) set(dnew, j = j, value = dnew[[j]] * modvec[, j])
    dnew[plot_res <= 0, plot_res := 0.00000001]
    dnew[sampled_area <= 0, sampled_area := 0.00000001]
    dnew[study_duration <= 0, study_duration := 0.00000001]
    dnew[t_btwn_samp < 0, t_btwn_samp := 0.00000001]

    dnew[, t_btwn_samp := to_infin_byond(t_btwn_samp)]  # set high
    dnew
  })
  return(bout)
}

set.seed(1)
bootperturb <- resamp_func(datf, p = p, iter = 1000)  # 10% perturb
# bootperturb2 <- resamp_func(datf, p = p, iter = 1000)  # 10% perturb
# all(bootperturb[[200]]$plot_res == bootperturb2[[200]]$plot_res)
# rm(bootperturb2)

```

<a href="#top">Back to top</a>

```{r, eval = FALSE, echo = FALSE}
### Bootstrapping
# Good old-fashioned bootstrapping with replacement, no perturbation of value
# bootstrap
set.seed(1)
bootsamp <- lapply(1:1000, function(x) {
  if((x / 100) %in% 1:100) print(x)
  dnew <- copy(datf[, .(plot_res, sampled_area, t_btwn_samp, study_duration)])
  dnew <- dnew[sample(1:.N, size = .N, replace = TRUE), ]
  dnew[, t_btwn_samp := to_infin_byond(t_btwn_samp)]  # set high
  dnew
})

```

<a href="#top">Back to top</a>

## Plots
### Scaling in log10 space
```{r, eval = FALSE}
i <- 0.0000001
j <- rep(0, 16)
for(k in 1:length(j)) {
  i <- i * 10
  j[k] <- i
}

# temporal scales
tdt <- data.table("scaleval" = j, "time" = j)
tdt[, tlog := log10(time)]

# labels for temporal axes
# return interval
tlab1 <- c(expression(paste(NULL<="second"^-1)), expression("minute"^-1),
           expression("hour"^-1), expression("day"^-1), 
           expression("week"^-1), expression("month"^-1),            
           expression("year"^-1), expression("decade"^-1),
           expression("century"^-1), 
           expression("millenium"^-1), "unreplicated")# expression(infinity))
taxis1 <- cbind.data.frame( 
  c(1 / (24 * 60 * 60), 1 / (24 * 60), 1 / 24, 1, 7, 30, 365, 365 * 10, 
    365 * 100, 365 * 1000, 365 * 10000))
taxis1 <- data.table(taxis1)
setnames(taxis1, names(taxis1), "days")
taxis1[, logdays := log10(days)]

tlab2 <- c(expression(NULL<="second"), "minute", "hour", "day", "week", "month",
           "year","decade", "century", "millenium", "10 KA")  
taxis2 <- cbind.data.frame(c(1 / (24 * 60 * 60), 1 / (24 * 60), 1 / 24, 1, 7, 
                             30, 365, 365 * 10, 365 * 100, 365 * 1000, 
                             365 * 10000))
taxis2 <- data.table(taxis2)
setnames(taxis2, names(taxis2), c("days"))
taxis2[, logdays := log10(days)]

# spatial
# plot(1:10, xlab = expression(paste("mm"^2)), xaxt = "n")
# axis(1, at = 1:8, labels = lab, las = 2)

# plot resolution
alab1 <- c(expression(paste(NULL<="0.01 cm"^2)), expression("0.1 cm"^2), 
           expression("1 cm"^2), expression("10 cm"^2),
           expression("100 cm"^2), expression("1000 cm"^2), 
           expression("1 m"^2), expression("10 m"^2),
           expression("100 m"^2), expression("1000 m"^2), 
           "1 ha", "10 ha", "100 ha", "1000 ha", 
           expression(paste(NULL>="10000 ha")))

aaxis1 <- cbind.data.frame(c(0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1,
                             1^2, 10, 10^2, 10^3, 10^4, 10^5, 10^6, 10^7, 10^8))
aaxis1 <- data.table(aaxis1)
setnames(aaxis1, names(aaxis1), "res")
aaxis1[, logres := log10(res)]

# sampled area
alab2 <- c(expression(paste(NULL<="0.1 m"^2)), expression("1 m"^2),
           expression("10 m"^2), 
           expression("100 m"^2), expression("1000 m"^2), expression("1 ha"),
           expression("10 ha"), expression("100 ha"), expression("1000 ha"), 
           expression(paste(10^4 , " ha")), expression(paste(10^5 , " ha")), 
           expression(paste(10^6 , " ha")), expression(paste(10^7 , " ha")), 
           expression(paste(10^8 , " ha")), expression(paste(10^9 , " ha")), 
           expression(paste(10^10 , " ha")))

aaxis2 <- cbind.data.frame(
  c(0.1 / 10000, 1 / 10000, 10 / 10000, 100 / 10000, 1000 / 10000, 1, 10, 10^2,
    10^3, 10^4, 10^5, 10^6, 10^7, 10^8, 10^9, 10^10))
aaxis2 <- data.table(aaxis2)
setnames(aaxis2, names(aaxis2), "area")
aaxis2[, logarea := log10(area)]

```

<a href="#top">Back to top</a>

### Perturbed set
```{r, eval = FALSE}
bootp_dt <- rbindlist(bootperturb)
resdat <- data.table(x = log10(bootp_dt$t_btwn_samp), 
                      y = log10(bootp_dt$plot_res))
resdat$n <- rep(1, nrow(resdat))
rx <- range(resdat$x)
rx <- round(rx / 0.5) * 0.5  # round to nearest 0.5
rx[1] <- -5
rx[2] <- 6.56
resdat[x < rx[1], x := rx[1]]
resdat[x > rx[2], x := rx[2]]
# rx[2] <- 7.6
ry <- range(aaxis1$logres)
ry[1] <- -5  # set limits to 0.01 cm^2
resdat[y < ry[1], y := ry[1]]
resdat[y > ry[2], y := ry[2]]
coordinates(resdat) <- ~x + y

# extent
extdat <- data.table(x = log10(bootp_dt$study_duration), 
                     y = log10(bootp_dt$sampled_area))
extdat$n <- rep(1, nrow(extdat))
ex <- range(taxis2$logdays)
ex <- c(floor(ex[1]), 5.56)#ceiling(ex[2]))
extdat[x < ex[1], x := ex[1]]
extdat[x > ex[2], x := ex[2]]
# ex <- round(ex / 0.5) * 0.5  # round to nearest 0.5
# ex[2] <- 7.6
ey <- range(aaxis2$logarea)
extdat[y < ey[1], y := ey[1]]
extdat[y > ey[2], y := ey[2]]
coordinates(extdat) <- ~x + y

# densities
# resolution
rres <- kdensity(rx[1], rx[2], ry[1], ry[2], 0.1, resdat, 1)
rres <- (rres / cellStats(rres, sum)) * 100
rng <- range(rres[is.finite(rres)])
# rng[2] <- 0.1
bwidth <- (rng[2] - rng[1]) / 30
brks <- seq(rng[1], rng[2], bwidth)
brklabs <- seq(0, 0.1, 0.02)#round(brks[seq(1, length(brks), 5)], 2)

# extent
rext <- kdensity(ex[1], ex[2], ey[1], ey[2], 0.1, extdat, 1)
rext <- (rext / cellStats(rext, sum)) * 100
rng <- range(rext[is.finite(rext)])
rng[2] <- 0.1
bwidth <- (rng[2] - rng[1]) / 30
brks2 <- seq(rng[1], rng[2], bwidth)
brklabs2 <- round(brks2[seq(1, length(brks2), 6)], 2)

# cols <- colorRampPalette(c("blue", "gold", "red"))
# cols <- c(rev(terrain.colors(30))[1], cols(29))

brkfun <- function(ext, ival, n) {
  rng <- range(ext[is.finite(ext)])
  bwidth <- (rng[2] - rng[1]) / n
  brks <- seq(rng[1], rng[2], bwidth)
  brklabs <- seq(0, round(rng[2], 2), ival)
  list("brks" = brks, "labs" = brklabs)
}
cuts <- 80

cxa = 0.7
pdf("paper/figures/res_v_extent_pbstrap2.pdf", width = 7, 
    height = 2.5)
par(mfrow = c(1, 2), mar = c(4, 4, 0.3, 3), oma = c(0, 0, 0, 1), 
    mgp = c(2, 0.5, 0))
# image(rres, col = cols, breaks = brks,
brks <- brkfun(rres, 0.01, cuts)  # breaks
image(rres, col = rev(terrain.colors(cuts)), #breaks = brks,
     axes = FALSE, xlab = "", ylab = "")
# plot(rres2, col = rev(terrain.colors(20)))
axis(1, at = taxis1$logdays[-c(5, 9, 10)], labels = tlab1[-c(5, 9, 10)], 
     las = 2, tcl = -0.2, cex.axis = cxa)
axis(2, at = aaxis1$logres[-1], labels = alab1[-1], las = 2, tcl = -0.2, 
     cex.axis = cxa)
# plot(rres2, axes = FALSE, legend.only = TRUE)
aargs <- list(mgp = c(3, 0.25, 0), at = brks$labs, labels = brks$labs, 
              cex.axis = cxa, tcl = -0.1)
plot(rres, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, col = rev(terrain.colors(cuts)))
brks <- brkfun(rext, 0.01, cuts)  # breaks
image(rext, col = rev(terrain.colors(cuts)), axes = FALSE, xlab = "", 
      ylab = "")
axis(1, at = taxis2$logdays[-5], labels = tlab2[-5], las = 2,
     cex.axis = cxa, tcl = -0.2)
axis(2, at = aaxis2$logarea, labels = alab2, las = 2, cex.axis = cxa,
     tcl = -0.2)
aargs <- list(mgp = c(3, 0.25, 0), at = brks$labs, labels = brks$labs, 
              cex.axis = cxa, tcl = -0.1)
plot(rext, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, col = rev(terrain.colors(cuts)))
dev.off()
```

<a href="#top">Back to top</a>

```{r, eval = FALSE, echo = FALSE}
### Bootstrap - deprecated for now

bootdt <- rbindlist(bootsamp)
resdat2 <- data.table(x = log10(bootdt$t_btwn_samp), y = log10(bootdt$plot_res))
resdat2$n <- rep(1, nrow(resdat2))
rx <- range(resdat2$x)
rx <- round(rx / 0.5) * 0.5  # round to nearest 0.5
rx[2] <- 6.56
resdat2[x < rx[1], x := rx[1]]
resdat2[x > rx[2], x := rx[2]]
ry <- range(aaxis1$logres)
ry[1] <- -5  # set limits to 0.01 cm^2
resdat2[y < ry[1], y := ry[1]]
resdat2[y > ry[2], y := ry[2]]
coordinates(resdat2) <- ~x + y

# extent
extdat2 <- data.table(x = log10(bootdt$study_duration), 
                      y = log10(bootdt$sampled_area))
extdat2$n <- rep(1, nrow(extdat2))
ex <- range(taxis2$logdays)
ex <- c(floor(ex[1]), 5.56)#ceiling(ex[2]))
extdat2[x < ex[1], x := ex[1]]
extdat2[x > ex[2], x := ex[2]]
ey <- range(aaxis2$logarea)
extdat2[y < ey[1], y := ey[1]]
extdat2[y > ey[2], y := ey[2]]
coordinates(extdat2) <- ~x + y

# densities
# resolution
rres2 <- kdensity(rx[1], rx[2], ry[1], ry[2], 0.1, resdat2, 1)
rres2 <- (rres2 / cellStats(rres2, sum)) * 100
rng <- range(rres2[is.finite(rres2)])
bwidth <- (rng[2] - rng[1]) / 30
brks <- seq(rng[1], rng[2], bwidth)
brklabs <- seq(0, 0.1, 0.02)#round(brks[seq(1, length(brks), 5)], 2)

# extent
rext2 <- kdensity(ex[1], ex[2], ey[1], ey[2], 0.1, extdat2, 1)
rext2 <- (rext2 / cellStats(rext2, sum)) * 100
rng <- range(rext2[is.finite(rext2)])
# rng[2] <- 0.1
bwidth <- (rng[2] - rng[1]) / 30
brks2 <- seq(rng[1], rng[2], bwidth)
brklabs2 <- brklabs #round(brks2[seq(1, length(brks2), 3)], 2)

cxa = 0.7
pdf("paper/figures/res_v_extent_bstrap2.pdf", width = 7, 
    height = 2.5)
par(mfrow = c(1, 2), mar = c(4, 4, 0.3, 3), oma = c(0, 0, 0, 1), 
    mgp = c(2, 0.5, 0))
# image(rres, col = cols, breaks = brks,
image(rres2, col = rev(terrain.colors(30)), breaks = brks,
     axes = FALSE, xlab = "", ylab = "")
# plot(rres2, col = rev(terrain.colors(20)))
axis(1, at = taxis1$logdays[-c(5, 9, 10)], labels = tlab1[-c(5, 9, 10)], 
     las = 2, tcl = -0.2, cex.axis = cxa)
axis(2, at = aaxis1$logres[-1], labels = alab1[-1], las = 2, tcl = -0.2, 
     cex.axis = cxa)
# plot(rres2, axes = FALSE, legend.only = TRUE)
aargs <- list(mgp = c(3, 0.25, 0), at = brklabs, labels = brklabs, 
              cex.axis = cxa, tcl = -0.1)
plot(rres2, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, breaks = brks, col = rev(terrain.colors(30)))

image(rext2, col = rev(terrain.colors(30)), axes = FALSE, xlab = "", 
      ylab = "", breaks = brks2)
axis(1, at = taxis2$logdays[-5], labels = tlab2[-5], las = 2,
     cex.axis = cxa, tcl = -0.2)
axis(2, at = aaxis2$logarea, labels = alab2, las = 2, cex.axis = cxa,
     tcl = -0.2)
aargs <- list(mgp = c(3, 0.25, 0), at = brklabs2, labels = brklabs2, 
              cex.axis = cxa, tcl = -0.1)
plot(rext2, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, breaks = brks2, col = rev(terrain.colors(30)))
dev.off()

# datf[, plot(log10(study_duration), log10(sampled_area), xlim)]
```

<a href="#top">Back to top</a>

### Primary dataset (main figure)
```{r, eval = FALSE}
resdat3 <- data.table(x = log10(to_infin_byond(datf$t_btwn_samp)), 
                      y = log10(datf$plot_res))
resdat3$n <- rep(1, nrow(resdat3))
rx <- range(resdat3$x)
rx <- round(rx / 0.5) * 0.5  # round to nearest 0.5
rx[2] <- 6.56
resdat3[x < rx[1], x := rx[1]]
resdat3[x > rx[2], x := rx[2]]
ry <- range(aaxis1$logres)
ry[1] <- -5  # set limits to 0.01 cm^2
resdat3[y < ry[1], y := ry[1]]
resdat3[y > ry[2], y := ry[2]]
coordinates(resdat3) <- ~x + y

# extent
extdat3 <- data.table(x = log10(datf$study_duration), 
                      y = log10(datf$sampled_area))
extdat3$n <- rep(1, nrow(extdat3))
ex <- range(taxis2$logdays)
ex <- c(floor(ex[1]), 5.56)#ceiling(ex[2]))
extdat3[x < ex[1], x := ex[1]]
extdat3[x > ex[2], x := ex[2]]
ey <- range(aaxis2$logarea)
extdat3[y < ey[1], y := ey[1]]
extdat3[y > ey[2], y := ey[2]]
coordinates(extdat3) <- ~x + y

# temporal framing
tempdat <- data.table(x = log10(to_infin_byond(datf$t_btwn_samp)), 
                      y = log10(datf$study_duration))
tempdat$n <- rep(1, nrow(tempdat))
tx <- range(tempdat$x)
tx <- round(rx / 0.5) * 0.5  # round to nearest 0.5
tx[2] <- 6.56
tempdat[x < rx[1], x := rx[1]]
tempdat[x > rx[2], x := rx[2]]
ty <- range(taxis2$logdays)
ty <- c(floor(ty[1]), 5.56)#ceiling(ex[2]))
tempdat[y < ty[1], y := ty[1]]
tempdat[y > ty[2], y := ty[2]]
coordinates(tempdat) <- ~x + y

# spatial framing
spatdat <- data.table(x = log10(datf$plot_res), y = log10(datf$sampled_area))
spatdat$n <- rep(1, nrow(spatdat))
sx <- range(aaxis1$logres)
sx[1] <- -5  # set limits to 0.01 cm^2
spatdat[x < sx[1], y := sx[1]]
spatdat[x > sx[2], y := sx[2]]
sy <- range(aaxis2$logarea)
spatdat[y < sy[1], y := sy[1]]
spatdat[y > sy[2], y := sy[2]]
coordinates(spatdat) <- ~x + y

# densities
# resolution
rres3 <- kdensity(rx[1], rx[2], ry[1], ry[2], 0.1, resdat3, 1)
rres3 <- (rres3 / cellStats(rres3, sum)) * 100
# rng <- range(rres3[is.finite(rres3)])
# bwidth <- (rng[2] - rng[1]) / 30
# brks <- seq(rng[1], rng[2], bwidth)
# brklabs <- seq(0, 0.12, 0.02)#round(brks[seq(1, length(brks), 5)], 2)
# brklabs <- seq(0, 0.1, 0.02)#round(brks[seq(1, length(brks), 5)], 2)

# extent
rext3 <- kdensity(ex[1], ex[2], ey[1], ey[2], 0.1, extdat3, 1)
rext3 <- (rext3 / cellStats(rext3, sum)) * 100
# rng <- range(rext3[is.finite(rext3)])
# # rng[2] <- 0.1
# bwidth <- (rng[2] - rng[1]) / 30
# brks2 <- seq(rng[1], rng[2], bwidth)
# brklabs2 <- brklabs #round(brks2[seq(1, length(brks2), 3)], 2)

# temporal
tres <- kdensity(tx[1], tx[2], ty[1], ty[2], 0.1, tempdat, 1)
tres <- (tres / cellStats(tres, sum)) * 100
# spatial
sres <- kdensity(sx[1], sx[2], sy[1], sy[2], 0.1, spatdat, 1)
sres <- (sres / cellStats(sres, sum)) * 100

brkfun <- function(ext, ival, n) {
  rng <- range(ext[is.finite(ext)])
  bwidth <- (rng[2] - rng[1]) / n
  brks <- seq(rng[1], rng[2], bwidth)
  brklabs <- seq(0, round(rng[2], 2), ival)
  list("brks" = brks, "labs" = brklabs)
}

# cxa = 0.7
ll <- 3.5
cxa = 0.8
stps <- sapply(c(3, 4), function(x) which(datf$st == x))  # IDs rs/auto/paleo
pchs <- list(1, "+")
cexs <- c(0.4, 0.6)
cuts <- 80

# pdf("paper/figures/res_v_extent.pdf", width = 7, height = 2.5)
pdf("paper/figures/kde43.pdf", width = 7, height = 5.5)
par(mfrow = c(2, 2), mar = c(6, 6, 0.3, 3), oma = c(0, 0, 0.5, 1), 
    mgp = c(2, 0.25, 0))
# resolutions
# image(rres3, col = rev(terrain.colors(30)), breaks = brks,
image(rres3, col = rev(terrain.colors(cuts)), axes = FALSE, xlab = "", 
      ylab = "")
axis(1, at = taxis1$logdays[-c(5, 10)], labels = tlab1[-c(5, 10)], 
     las = 2, tcl = -0.2, cex.axis = cxa)
axis(2, at = aaxis1$logres[-1], labels = alab1[-1], las = 2, tcl = -0.2, 
     cex.axis = cxa)
mtext("Sampling interval", 1, cex = cxa, line = ll)
mtext("Spatial resolution", 2, cex = cxa, line = ll)
brks <- brkfun(rres3, 0.01, cuts)  # breaks
aargs <- list(mgp = c(3, 0.25, 0), at = brks$labs, labels = brks$labs, 
              cex.axis = cxa, tcl = -0.1)
plot(rres3, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     #legend.shrink = 0.9, breaks = brks, col = rev(terrain.colors(30)))
     legend.shrink = 0.9, col = rev(terrain.colors(cuts)))
mtext("A", side = 3, line = -1, cex = 0.8, adj = 0.05)
# for(i in 1:length(stps)) {
#   points(resdat3$x[stps[[i]]], resdat3$y[stps[[i]]], pch=pchs[[i]], cex=cexs[i])
# }

# extents
# image(rext3, col = rev(terrain.colors(30)), axes = FALSE, xlab = "", 
image(rext3, col = rev(terrain.colors(cuts)), axes = FALSE, xlab = "", 
      ylab = "")#, breaks = brks2)
axis(1, at = taxis2$logdays[-5], labels = tlab2[-5], las = 2,
     cex.axis = cxa, tcl = -0.2)
axis(2, at = aaxis2$logarea, labels = alab2, las = 2, cex.axis = cxa,
     tcl = -0.2)
brks <- brkfun(rext3, 0.01, cuts)  # breaks
aargs <- list(mgp = c(3, 0.25, 0), at = brks$labs, labels = brks$labs, 
              cex.axis = cxa, tcl = -0.1)
mtext("Temporal duration", 1, cex = cxa, line = ll)
mtext("Spatial extent", 2, cex = cxa, line = ll)
plot(rext3, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     #legend.shrink = 0.9, breaks = brks2, col = rev(terrain.colors(30)))
     legend.shrink = 0.9, col = rev(terrain.colors(cuts)))
mtext("B", side = 3, line = -1, cex = 0.8, adj = 0.05)
# for(i in 1:length(stps)) {
#   points(extdat3$x[stps[[i]]], extdat3$y[stps[[i]]], pch=pchs[[i]], cex=cexs[i])
# }

# spatial
image(sres, col = rev(terrain.colors(cuts)), axes = FALSE, xlab = "", 
      ylab = "")
# points(spatdat$x, spatdat$y, cex = 0.1)
axis(1, at = aaxis1$logres, labels = alab1, las = 2, tcl = -0.2, cex.axis = cxa)
axis(2, at = aaxis2$logarea, labels = alab2, las = 2, tcl = -0.2, 
     cex.axis = cxa)
mtext("Spatial resolution", 1, cex = cxa, line = ll)
mtext("Spatial extent", 2, cex = cxa, line = ll)
brks <- brkfun(sres, 0.01, cuts)  # breaks
aargs <- list(mgp = c(3, 0.25, 0), at = brks$labs, labels = brks$labs, 
              cex.axis = cxa, tcl = -0.1)
plot(sres, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, col = rev(terrain.colors(cuts)))
mtext("C", side = 3, line = -1, cex = 0.8, adj = 0.05)
# for(i in 1:length(stps)) {
#   points(spatdat$x[stps[[i]]], spatdat$y[stps[[i]]], pch=pchs[[i]], cex=cexs[i])
# }

# temporal
image(tres, col = rev(terrain.colors(cuts)), axes = FALSE, xlab = "", ylab = "")
# points(spatdat$x, spatdat$y, cex = 0.1)
axis(1, at = taxis1$logdays[-c(5, 10)], labels = tlab1[-c(5, 10)], 
     las = 2, tcl = -0.2, cex.axis = cxa)
axis(2, at = taxis2$logdays[-5], labels = tlab2[-5], las = 2,
     cex.axis = cxa, tcl = -0.2)
mtext("Sampling interval", 1, cex = cxa, line = ll)
mtext("Temporal duration", 2, cex = cxa, line = ll)
brks <- brkfun(tres, 0.02, cuts)  # breaks
aargs <- list(mgp = c(3, 0.25, 0), at = brks$labs, labels = brks$labs, 
              cex.axis = cxa, tcl = -0.1)
plot(tres, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, col = rev(terrain.colors(cuts)))
mtext("D", side = 3, line = -1, cex = 0.8, adj = 0.05)
# for(i in 1:length(stps)) {
#   points(tempdat$x[stps[[i]]], tempdat$y[stps[[i]]], pch=pchs[[i]], cex=cexs[i])
# }
dev.off()

# datf[, plot(log10(study_duration), log10(sampled_area), xlim)]

# image(rres3, col = rev(terrain.colors(100)))
# points(resdat3$x, resdat3$y, pch = 20, cex = 0.5)
image(sres, col = rev(terrain.colors(100)))
points(spatdat$x, spatdat$y, pch = 20, cex = 0.5)
```

<a href="#top">Back to top</a>

## Stats and supplementary plots 

### Statistics
```{r, eval=FALSE}
length(which(dat$study_type %in% 
               c("remote sensing", "other geographic data"))) / nrow(dat)
length(which(dat$study_type %in% 
               c("remote sensing", "other geographic data"))) / nrow(dat)
dat[t_btwn_samp == 0, .N] / dat[, .N]  # 35% of samples are once-offs
dat[study_duration == samp_duration, .N] / nrow(dat)
dat[(study_duration == samp_duration) & t_btwn_samp != 0]
dat[(study_duration != samp_duration) & t_btwn_samp == 0]

hdat <- cbind("res" = log10(datf$plot_res), "ext" = log10(datf$sampled_area), 
              "int" = log10(to_infin_byond(datf$t_btwn_samp)), 
              "dur" = log10(datf$study_duration))
hdat <- data.table(hdat)
# set bounds for histograms
hdat[res < aaxis1$logres[1], res := aaxis1$logres[1]]
hdat[res > ry[2], res := ry[2]]
hdat[ext < -6, ext := -6]  # set minimum extent -6 (0.01 m2)

# hist(hdat$res, breaks = aaxis1$logres)
# hist(log10(datf$plot_res), breaks = resbrks)
# hist(log10(datf$plot_res), breaks = resbrks)

mga <- -0.34
sfigl <- -1.2
cxa <- 0.8
cxl <- 0.9
reds <- brewer.pal(9, name = "Reds")
blues <- brewer.pal(9, name = "Blues")
plot(1:2, pch = 20, col = blues[c(4, 6)])
yl <- 35
# pdf("paper/figures/hists.pdf", width = 7, height = 2.5)
pdf("paper/figures/hists2.pdf", width = 5, height = 5)
par(mfrow = c(2, 2), mar = c(4.5, 1, 1, 1), oma = c(2, 3, 0, 0))
# resolution
h <- hist(hdat$res, breaks = aaxis1$logres, plot = FALSE)
h$density <- h$counts / sum(h$counts) * 100
plot(h, freq = FALSE, ylab = "", las = 2,  xaxt = "n", mgp = c(3.25, 0.25, mga),
     tcl = -0.2, cex.axis = cxa, xlab = "Spatial resolution", 
     ylim = c(0, yl - 10), main = "", col = reds[4], cex.lab = cxl)
axis(1, at = aaxis1$logres, labels = alab1, las = 2, cex.axis = cxa, 
     tcl = -0.2, mgp = c(2, 0.25, mga))
mtext("Percent of observations", side = 2, line = 1.5, cex = 0.8)
mtext("A", side = 3, line = sfigl, cex = 0.8, adj = 0.05)

# extent
h <- hist(hdat$ext, breaks = c(-6, aaxis2$logarea), plot = FALSE)
h$density <- h$counts / sum(h$counts) * 100
plot(h, freq = FALSE, ylab = "", las = 2,  xaxt = "n", mgp = c(3.25, 0.25, mga),
     tcl = -0.2, cex.axis = cxa, xlab = "Spatial extent", ylim = c(0, yl - 10), 
     main = "", col = reds[6], cex.lab = cxl)
axis(1, at = c(-6, aaxis2$logarea), 
     labels = c(expression(paste(NULL<="0.01m"^2)), expression(paste(0.1, m^2)), 
                alab2[-1]), las = 2, cex.axis = cxa,
     tcl = -0.2, mgp = c(2, 0.25, mga))
mtext("B", side = 3, line = sfigl, cex = 0.8, adj = 0.05)

# interval
tax <- c(taxis2$logdays[-c(10:11)], mean(taxis2$logdays[c(10:11)]))
h <- hist(hdat$int, breaks = taxis1$logdays, plot = FALSE)
h$density <- h$counts / sum(h$counts) * 100
plot(h, freq = FALSE, ylab = "", las = 2,  xaxt = "n", mgp = c(3.25, 0.25, mga),
     tcl = -0.2, cex.axis = cxa, xlab = "Sampling interval", ylim = c(0, yl), 
     main = "", col = blues[4], cex.lab = cxl)
axis(1, at = tax, labels = tlab1[-10], las = 2, cex.axis = cxa, 
     tcl = -0.2, mgp = c(2, 0.25, -0.34))
mtext("C", side = 3, line = sfigl, cex = 0.8, adj = 0.05)
mtext("Percent of observations", side = 2, line = 1.5, cex = 0.8)

# duration
# tax <- c(taxis2$logdays[-c(10:11)], mean(taxis2$logdays[c(10:11)]))
h <- hist(hdat$dur, breaks = taxis2$logdays, plot = FALSE)
h$density <- h$counts / sum(h$counts) * 100
plot(h, freq = FALSE, ylab = "", las = 2,  xaxt = "n", mgp = c(3.25, 0.25, mga),
     tcl = -0.2, cex.axis = cxa, xlab = "Temporal duration", ylim = c(0, yl), 
     main = "", col = blues[6], cex.lab = cxl)
axis(1, at = taxis2$logdays, labels = tlab2, las = 2, cex.axis = cxa, 
     tcl = -0.2, mgp = c(2, 0.25, mga))
mtext("D", side = 3, line = sfigl, cex = 0.8, adj = 0.05)

dev.off()

# stats
axisl <- list(aaxis1$logres, c(-6, aaxis2$logarea), taxis1$logdays,
              taxis2$logdays)
hdatstat <- lapply(1:4, function(x) {
  h <- hist(hdat[[x]], breaks = axisl[[x]], plot = FALSE)
  h$density <- h$counts / sum(h$counts) * 100
  h
})

# res
l <- length(hdatstat[[1]]$density)
sum(hdatstat[[1]]$density[4:6])  # 55 % between 10cm^2 and 1 m^2
sum(hdatstat[[1]]$density[1:6])  #  69% < 1m^2
sum(hdatstat[[1]]$density[7:10]) # 22 % between 1 m^2 and 1 ha
sum(hdatstat[[1]]$density[11:(l)]) # 9 % 1-10000 ha
# dat[plot_res >= 10000^2]

# length(which(hdat$res >= -3 & hdat$res <= 0)) / length(hdat$res)
# length(which(hdat$res <= 4)) / length(hdat$res)
# sum(hdatstat[[1]]$counts[4:6]) / sum(hdatstat[[1]]$counts)

# extent
l <- length(hdatstat[[2]]$density)
sum(hdatstat[[2]]$density[1:2])  # 35 % < 1 m^2
sum(hdatstat[[2]]$density[1:6])  # 82% < 1 ha
sum(hdatstat[[2]]$density[1:7])  # 86% < 10 ha
sum(hdatstat[[2]]$density[1:8])  # 89 % < 100 ha
sum(hdatstat[[2]]$density[1:9])  # 92 % < 1000 ha
sum(hdatstat[[2]]$density[8:9])  # 6 % 10-1000 ha
sum(hdatstat[[2]]$density[8:l])  # 14% > 10 ha
sum(hdatstat[[2]]$density[10:l]) # 8.4 % covered an area > 1000 ha
sum(hdatstat[[2]]$density[12:l]) # 5.1 % covered an area > 100,000 ha
sum(hdatstat[[2]]$density[13:l]) # 4.1 % covered an area > 1,000,000 ha

# length(which(hdat$ext < -4)) / length(hdat$ext)
# length(which(hdat$ext > 3)) / length(hdat$ext)
# length(which(hdat$ext > 1 & hdat$ext <= 3)) / length(hdat$ext)
# which(hdatstat[[2]]$breaks == log10(1000000))
# length(hdatstat[[2]]$counts[7:8])
# hdatstat[[2]]$mids[12]

# interval
l <- length(hdatstat[[3]]$density)
sum(hdatstat[[3]]$density[l])  # 36% are once-offs
sum(hdatstat[[3]]$density[1:3])  # 17 % < daily
sum(hdatstat[[3]]$density[1:4])  # 17 % < daily
sum(hdatstat[[3]]$density[4:5])  # 19% daily up to monthly
sum(hdatstat[[3]]$density[6])  # 23% monthly up to yearly
sum(hdatstat[[3]]$density[7:9]) # 5 % yearly to decadal

# duration
l <- length(hdatstat[[4]]$density)
sum(hdatstat[[4]]$density[1:3])  # 69 % up to 1 day
sum(hdatstat[[4]]$density[4:5])  # 19% covered between 1 day and 1 month
sum(hdatstat[[4]]$density[6])  # 8% covered between 1 month and 1 year
# sum(hdatstat[[4]]$density[4:6])  # 26% covered between 1 day and 1 year
sum(hdatstat[[4]]$density[7:10]) # 5% year to century

# datf[, plot(log10(n_sites), log10(plot_res))]
# dat[like(study_type, "field"), plot(log10(n_sites), log10(plot_res))]
datf[like(study_type, "field"), plot(log10(plot_res), log10(sampled_area), 
                                     ylim = c(-10, 10))]

datf[like(study_type, "remote"), 
     points(log10(plot_res), log10(sampled_area), pch = 20, col = "red")]
datf[like(study_type, "automated"), 
     points(log10(plot_res), log10(sampled_area), pch = 20, col = "blue")]
lines(aaxis1$logres, aaxis2$logarea[-16] )
datf[, .N / nrow(datf) * 100, by = st]

datf[, plot(log10(t_btwn_samp), log10(study_duration), pch = 20)]
datf[which(hdat[[3]] < -1.380211), 
     points(log10(t_btwn_samp), log10(study_duration), pch = 20, col = "blue")]
datf[like(study_type, "automated"), 
     points(log10(t_btwn_samp), log10(study_duration), pch = 20, col = "red")]


# points(resdat3$x[which(datf$st == 4)], resdat3$y[which(datf$st == 4)])
# points(resdat3$x[which(datf$st == 1)], resdat3$y[which(datf$st == 1)])

# types of observations
# unique(datf$study_type)
datf[like(study_type, "field"), .N] / nrow(datf)  # 80% field studies
datf[like(study_type, "auto"), .N] / nrow(datf) # 12 % automated
datf[like(study_type, "auto") & log10(t_btwn_samp) < -1.380211, .N] /   length(which(hdat[[3]] < -1.380211))  # 75% 

datf[like(study_type, "remote|other"), .N] / nrow(datf) # 6 % automated
datf[like(study_type, "paleo"), .N] / nrow(datf) * 100 # 1 % automated

```

<a href="#top">Back to top</a>


### Sensitivity
Just for the four main variables. Rules: 

+ If `plot_res` and/or `n_sites` uncertain, then `sampled_area` must be. Recalculate using random draw within the uncertain variable 
+ If `t_btwn_samp` and/or `samp_duration` uncertain, do the same as above, but we have no variable for n repeats for calculating `study_duration`.

```{r}
svars <- c("plot_res", "n_sites", "sampled_area", "samp_duration",
           "t_btwn_samp", "study_duration")

sens <- gsub("\\\\", ";", dat$sensitivity)
sens <- gsub(", ", ";", gsub("; ", ";", sens))
sens <- tolower(sens)
sensl <- strsplit(sens, ";")
# unique(unlist(sensl))

sens2 <- gsub("plo_", "plot_", sens)  # fix this one
sens2 <- gsub("[[:blank:]]", "_", sens2)  # replace spaces with _

corrtab <- cbind(c("^res", "plo_res", "sample_area", "samples_area", 
                   "sampled area",
                   "t_btwn_samples", "t_btwn_sample", "t_btwn_samp_samp", 
                   "t_twn_samp", "t_btw_samp", "samp_duratiion", 
                   "sampling_duration", "sample_duration", 
                   "plot_resolution", "number_of_sites", 
                   "time_between_sampling", "plot_size", 
                   "time_between_samples", "samp_study", ":", " ", ";_"), 
                 c(svars[c(1, 1, 3, 3, 3, 5, 5, 5, 5, 5, 4, 4, 4, 1, 2,
                           5, 1, 5)], "samp;study", ";", ";", ";"))

for(i in 1:nrow(corrtab)) {
  sens2 <- gsub(corrtab[i, 1], corrtab[i, 2], sens2)
}
# gsub("[a-z]( )[a-z]", "_", sens[[228]])
# sens[[228]]
# sens2[is.na(sens2)]
sens2[is.na(sens2)] <- "none"
sensl2 <- lapply(1:length(sens2), function(x) strsplit(sens2[x], ";")[[1]])
# unique(unlist(sensl))
# unique(unlist(sensl2))

# create a sensitivity table
senst <- do.call(cbind.data.frame, lapply(svars, function(x) {
  v <- sapply(sensl2, function(y) ifelse(any(y == x), 1, 0))
  # ifelse(is.na(v), 0, v)
}))
colnames(senst) <- c("res", "n", "sarea", "sampd", "tbtwn", "studyd")

# add column for uncertainty about n repeats
# senst$nrep <- rep(0, nrow(senst))

# i <- 300:305
# sensl2[i]
# senst[i, ]

# apply fixes (mostly to account for observer omissions)

# 1. if samp_duration OR t_btwn_samp is uncertain, study_duration must also be. 
id <- which((senst$sampd == 1 | senst$tbtwn == 1) & senst$studyd == 0)
senst[id, "studyd"] <- 1 

# 2. if study_duration is uncertain but t_btwn and samp_duration are not, treat
# both as uncertain
# although it is possible that just n_repeats is uncertain, but more likely 
# that observers didn't note this is sensitive. 
id <- which(senst$tbtwn == 0 & senst$sampd == 0 & senst$studyd == 1)
senst[id, c("sampd", "tbtwn")] <- 1

# 3. if plot_res or n_sites is uncertain, then sampled_area must be
id <- which((senst$res == 1 | senst$n == 1) & senst$sarea == 0)
senst[id, "sarea"] <- 1

# percentage of records that are uncertain
round(colSums(senst) / nrow(senst) * 100, 1)

```

<a href="#top">Back to top</a>

### Varying kernel sizes
```{r,eval = FALSE}
# resolution data
# resdat <- data.table(x = log10(datf$t_btwn_samp), y = log10(datf$plot_res))
# resdat$n <- rep(1, nrow(resdat))
# coordinates(resdat) <- ~x + y
# rx <- range(resdat$x)
# # rx <- range(aaxis$logarea)
# rx <- round(rx / 0.5) * 0.5  # round to nearest 0.5
# # rx[1] <- -6.5  # set temporal interval to -6.5 to have null returns centered
# # ry <- range(resdat$y)
# ry <- range(aaxis$logarea)
# ry <- round(ry / 0.5) * 0.5  # round to nearest 0.5
# 
# # extent data
# # fix area rounded to zero in Jon's plots
# extdat <- data.table("x" = log10(dat$study_duration), 
#                      "y" = log10(dat$sampled_area)) 
# # extdat[is.infinite(x), ]; extdat[is.infinite(y), ]
# 
# extdat$n <- rep(1, nrow(extdat))
# coordinates(extdat) <- ~x + y
# # ex <- range(extdat$x)
# ex <- range(taxis2$logdays)
# ex <- round(ex / 0.5) * 0.5  # round to nearest 0.5
# # ex[1] <- -5
# ey <- range(extdat$y)
# ey <- round(ey / 0.5) * 0.5  # round to nearest 0.5

# density rasters
# vary the kernel size about them
kernsl <- lapply(c(0.4, 0.7, 1), function(x) {
  rr <- kdensity(rx[1], rx[2], ry[1], ry[2], 0.1, resdat3, x)
  rr <- (rr / cellStats(rr, sum)) * 100
  er <- kdensity(ex[1], ex[2], ey[1], ey[2], 0.1, extdat3, x)
  er <- (er / cellStats(er, sum)) * 100
  kerns <- list("res" = rr, "ext" = er)
})

cxa <- 1.25

# As separate plots
pdf("paper/figures/res_v_extent_ksize.pdf", width = 8, height = 10)
par(mfrow = c(3, 2), oma = c(6, 3, 0, 0), mar = c(1, 5, 3, 4))
lapply(1:4, function(i) {
  x <- kernsl[[i]]
  # x <- kernsl[[1]]
  image(x$res, col = rev(terrain.colors(80)), axes = FALSE, xlab = "", 
        ylab = "")#, ylim = range(aaxis1$logarea))
  if(i == 3) {
    axis(1, at = taxis1$logdays[-c(5, 9, 10)], labels = tlab1[-c(5, 9, 10)], 
         las = 2, tcl = -0.2, cex.axis = cxa)
  }
  axis(2, at = aaxis1$logres[-1], labels = alab1[-1], las = 2, tcl = -0.2, 
       cex.axis = cxa)  
  aargs <- list(mgp = c(3, 0.25, 0), #at = brklabs, labels = brklabs, 
                cex.axis = cxa, tcl = -0.1)
  plot(x$res, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
     legend.shrink = 0.9, #breaks = brks, 
     col = rev(terrain.colors(0)))
  
  image(x$ext, col = rev(terrain.colors(80)), axes = FALSE, xlab = "", 
        ylab = "")
  if(i == 3) {
    axis(1, at = taxis2$logdays[-5], labels = tlab2[-5], las = 2,
         cex.axis = cxa, tcl = -0.2)
  }
  axis(2, at = aaxis2$logarea, labels = alab2, las = 2, cex.axis = cxa,
       tcl = -0.2)
  aargs <- list(mgp = c(3, 0.25, 0), #at = brklabs2, labels = brklabs2, 
                cex.axis = cxa, tcl = -0.1)
  plot(x$ext, legend.only = TRUE, axis.args = aargs, legend.width = 1.25,
       legend.shrink = 0.9, #breaks = brks2, 
       col = rev(terrain.colors(80)))
})
par(xpd = NA)
xx <- grconvertX(0.5, from = "ndc", to = "inches")
ii <- c(0.4, 0.6, 0.8, 1)
yy <- c(0.95, 0.75, 0.5, 0.25)
# yy <- c(-1, -5, -10, -20)
for(i in 1:length(ii)) {
  y <- grconvertY(yy[i], from = "ndc", to = "inches")
  # text(x = xx, y = y, labels = paste("kernel =", ii[i]))
  # par(xpd = NA)
  # mtext(text = paste("kernel =", ii[i]), side = 3, line = yy[i])
}
dev.off()

# plot(rrs, xlim = c(-5, 15), ylim = c(-5, 15), 
#      xlab = "Sample interval - log10(days)", 
#      ylab = "Plot resolution - log10(m^2)")
# plot(ers, box = FALSE, xlim = c(-5, 15), ylim = c(-5, 15), 
#      xlab = "Study duration - log10(days)", ylab = "Sampled area - log10(ha)")
# dev.off()
```

<a href="#top">Back to top</a>

### Scale diversity within study
```{r}
# plot resolution
doin <- datf[, .N, by = DOI]  # n obs/DOI
resuni <- datf[, length(unique(plot_res)), by = DOI]  # unique resolutions
resrng <- datf[, diff(range(plot_res)), by = DOI]
rescv <- datf[DOI %in% resuni[V1 > 1, DOI], cv(plot_res), by = DOI]
ressd <- datf[DOI %in% resuni[V1 > 1, DOI], log10(sd(plot_res)), by = DOI]
resmu <- datf[DOI %in% resuni[V1 > 1, DOI], log10(mean(plot_res)), by = DOI]
# plot(resuni$V1, resrng$V1)
# plot(resmu$V1, ressd$V1)
# plot(resmu$V1, rescv$V1)

# sampling interval
intuni <- datf[, length(unique(t_btwn_samp)), by = DOI]  # unique intervals
intrng <- datf[, diff(range(t_btwn_samp)), by = DOI]
intcv <- datf[DOI %in% intuni[V1 > 1, DOI], cv(t_btwn_samp), by = DOI]
intsd <- datf[DOI %in% intuni[V1 > 1, DOI], log10(sd(t_btwn_samp)), by = DOI]
intmu <- datf[DOI %in% intuni[V1 > 1, DOI], log10(mean(t_btwn_samp)), by = DOI]

# Plot Resolution Statistics
round(c("%" = length(which(resuni$V1 > 1)) / resrng[, .N],  # % > 1 res 
        "medrng" = resrng[which(resuni$V1 > 1), median(V1)],  # median res rng
        "murng" = resrng[which(resuni$V1 > 1), mean(V1)] / 10000,  # mu res rng
        "rescv" = rescv[, mean(V1)], # mean resolution CV
        "resmu" = resmu[, mean(V1)],
        "muN" = resuni[, mean(V1)]), 2)  # mean number of resolutions

# Plot Resolution Statistics
round(c("%" = length(which(intuni$V1 > 1)) / intrng[, .N],  # % > 1 interval
        "medrng" = intrng[which(intuni$V1 > 1), median(V1)],  # median int range
        "murng" = intrng[which(intuni$V1 > 1), mean(V1)],  # mean interval range
        "intcv" = intcv[, mean(V1)], # mean intolution CV
        "intmu" = intmu[, mean(V1)],
        "muN" = intuni[, mean(V1)]), 2)  # mean number of intolutions
```

<a href="#top">Back to top</a>