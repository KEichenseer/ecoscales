---
title: "Analysis of Calibration Dataset"
output: 
  rmarkdown::html_vignette:
    toc: yes
    number_sections: true
    toc_depth: 3
    fig_caption: true
vignette: >
  %\VignetteIndexEntry{2. Analysis of Calibration Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

# Overview

Analysis of calibration dataset used to assess between observer uncertainties.

```{r, message=FALSE, warning = FALSE}
library(ecoscales)
library(readxl)
library(Agreement)
library(irr)

```

```{r, eval=FALSE, echo = FALSE}
# Read in and clean-up calibration data
# cal <- data.table(read_excel(fp(p_dat, "merged_calibration.xlsx")))
# cal[, DOI := gsub("DOI:|doi:|DOI: |doi: |DOI ", "", DOI)]
# cal[, DOI := gsub("\\s", "", DOI)]  # remove DOI and whitespace
# names(cal)
# dropnm <-  c("V29")#, "V31", "journal", "exclusion reason", "sensitivity")
# cal[, c(dropnm) := NULL]
# 
# # check data types
# for(j in names(cal)[8:24]) set(cal, j = j, value = as.numeric(cal[[j]]))
# 
# # use NA in n_sites as indicator that study was excluded
# cal[, inout := ifelse(is.na(n_sites), 0, 1)]  
# write.csv(cal, file = fp(p_dat, "merged_calibrationf.csv"))
```

# Data
```{r, warning = FALSE}
# external fixes and recodes, bring back in
calfile <- system.file("extdata", "calibration-set.xlsx", package ="ecoscales")
cal <- data.table(read_excel(calfile))
# cal <- data.table(read_excel(fp(p_dat, "archive/merged_calibrationffffff.xlsx")))
# names(cal)

cal[, c("notes", "V31") := NULL]
nuvars <- c("inout", "feature", "study_year", "st", "plot_res", "n_sites",
            "act_ext", "eff_ext", "samp_dur", "t_btwn_samp", "act_dur", 
            "eff_dur", paste0("comp", 1:3), paste0("struc", 1:3), 
            paste0("func", 1:3))
for(j in nuvars) {
  set(cal, j = j, value = as.numeric(cal[[j]]))
}
# length(which(is.na(cal$feature)))

```

# Analyses
## Agreement on studies included/excluded
```{r}
# ndois <- cal[, unique(DOI)]  # check on number of journals

# reduce within-observer DOI duplicates 
dois <- cal[, unique(DOI), by = .(observer, inout)]

# recast dataset to obsevers in columns, inout as value, DOI as case
dois_c1 <- dcast(dois, V1 ~ observer, value.var = "inout")

# Fleiss's Kappa
kappam.fleiss(dois_c1[, 2:7, with = FALSE])
```

## Inter-rater reliability using number of records per paper
```{r}
doisum <- dcast(cal, DOI ~ observer, value.var = "inout", fun = sum)
# kappam.fleiss(doisum[, 2:7, with = FALSE])
icc(ratings = doisum[, 2:7, with = FALSE], model = "twoway")

```

```{r, warning = FALSE, fig.cap="Figure 1: Number of records extracted by each rater (observer) for each of the 20 papers in the calibration set.", fig.width=6, fig.height = 4}
doimat <- t(doisum[, -1, with = FALSE])
cols <- RColorBrewer::brewer.pal(n = 6, "Paired")#[c(3:1, 4:6)]
cxs <- seq(3, 0.8, length.out = 6)
pchs <- c(rep(20, 5), 4)
par(mar = c(4, 4, 0.1, 0.1))
plot(c(1, 20), c(0, 10), pch = "", xlab = "Paper reviewed", 
     ylab = "N extractable records", mgp = c(1.45, 0.5, 0), tcl = -0.2)
polygon(x = c(0, 21, 21, 0, 0), y = c(-1, -1, 11, 11, 0), col = "grey70")
# plot(doimat[1, ], pch = 20, xlab = "Paper reviewed", 
#      ylab = "N extractable records", cex = cxs[1], col = cols[1])
for(i in 1:6) points(doimat[i, ], col = cols[i], pch = pchs[i], cex = cxs[i])
legend(x = "topleft", pch = pchs, pt.cex = cxs, col = cols, 
       legend = paste0("Rater", 1:6), bty = "n")

```

## Variance in extracted statistics
### By DOI
```{r}
varnms <- c("plot_res", "n_sites", "act_ext", "eff_ext", "t_btwn_samp", 
            "act_dur", "eff_dur")
mus <- cal[inout == 1, lapply(.SD, mean, na.rm = TRUE), by = .(DOI, observer),             .SDcols = varnms]  # mean variable val per paper per observer
# variance and mean per paper across observers
vars <- mus[, lapply(.SD, sd, na.rm = TRUE), by = DOI, .SDcols = varnms] 
musmu <- mus[, lapply(.SD, mean, na.rm = TRUE), by = DOI, .SDcols = varnms]

# par(mfrow = c(3, 3), mar = c(3, 3, 2, 2), mgp = c(1.5, 0.5, 0))
# for(i in varnms) {
#   mu <- musmu[, get(i)]
#   sdev <- vars[, get(i)]
# #   print(paste(i, ":", sdev))
#   print(paste(i, ":", round(mu, 2), ":", round(sdev, 2), ":", 
#               round(sdev / mu, 2)))
#   # plot(mu, sdev / mu, xlab = "mean", ylab = "CV", main = i)
#   plot(mu, sdev, xlab = "mean", ylab = "sd", main = i)
# }

vars[, lapply(.SD, mean, na.rm = TRUE), .SDcols = varnms]
round(colMeans(sapply(varnms, function(i) {
  mu <- musmu[, get(i)]
  sdev <- vars[, get(i)]
  sdev / mu
}), na.rm = TRUE), 3)

# calr[DOI == "10.1007/s00442-005-0338-3" & feature == 2]
```


### By feature (individual records) across DOIs
```{r, results='hold'}
CV <- function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)
rnms <- c("DOI", "feature", "observer", "plot_res", "n_sites", 
          "act_ext", "eff_ext", "t_btwn_samp", "act_dur", "eff_dur")
calr <- cal[, rnms, with = FALSE]

# calr[feature != 99, ]
# calr[feature != 99, lapply(.SD, mean), by = .(DOI, feature), 
#      .SDcols = rnms[4:7]]
# calr[feature != 99, .N, by = .(DOI, feature)]
mymu <- function(x) round(mean(x, na.rm = TRUE), 3)
calr[feature != 99, lapply(.SD, CV), by = .(DOI, feature), 
     .SDcols = rnms[4:10]][, lapply(.SD, mymu), 
                          .SDcols = rnms[4:10]]

# par(mfcol = c(10, 4), mar = c(2, 2, 2, 2), mgp = c(1.5, 0.5, 0))
# mus[, plot(plot_res), by = DOI]

```



